# Note: For every run of the script, Data Pipeline, IAM roles and
#       CloudWatch Alarms are deleted/updated based on their name.
#       Please use unique names for these to avoid unintended actions on the objects.

# General Settings
[general]
# Access keys of the created IAM user for ELK
aws_access_key_id=<aws_access_key_id>
aws_secret_access_key=<aws_secret_access_key>

# AWS Region where ELK is operating. All objects are expected to be created in this region.
aws_region=us-east-1

# AWS Region endpoint to be used by Opsworks connection
opsworks_region=us-east-1

# OpsWorks Settings
[opsworks]
# The OpsWorks ID of the Shipper, Redis and Indexer Layers. 
# The three node types are expected to be implemented as layers in an OpsWorks stack.
shipper_opsworks_layer_id=e240d8ec-3ca2-46aa-af15-4e0c82a07250
redis_opsworks_layer_id=7694b00e-2a46-46d0-acc6-e50afe47dcac
indexer_opsworks_layer_id=3d06a30d-098e-4dfc-ac8e-a2a94686166e

[custom_script]
# S3 bucket and directory where custom scripts will be uploaded.
# Create this in the same region. Do not forget trailing slash on directory.
s3_bucket=roy-testbucket
s3_bucket_directory=sch-scripts/

# Defined cooldown period during scaledown activities to allow shipper and 
# indexer nodes to drain their buffers before they are scaled down.
cooldown_period_minutes=5

# S3 bucket and directory where the logs to be processed by the shipper are stored. 
# Expected to exist in the same region. Do not forget trailing slash on directory.
shipper_source_s3_bucket=roy-testbucket
shipper_s3_bucket_directory=test/

# CloudWatch Settings
[cloudwatch]
# The existing Logstash Buffer Metric
logstash_buffer_metric_namespace=Logstash
logstash_buffer_metric_name=RedisItemsQueued

# Existing Topic ARN used by SCH for notification
topic_arn=arn:aws:sns:us-east-1:092658368226:TestRoyForSCH

# Custom CloudWatch metrics to use for handling of overrunning of pipeline.
# Do not use names that include spaces.
elk_pipeline_metric_namespace=Pipeline
elk_pipeline_metric_name=ELK

# Defined acceptable running duration of the nodes. 
# CloudWatch Alarm will alert if this period is reached.
overrunning_threshold_minutes=120

# CloudWatch Alarm names to be used for handling of overrunning of the pipeline. 
# Note that alarms are deleted and recreated.
cw_alarm_elk_pipeline=ELK_Pipeline_Status

# Data Pipeline Settings
[data_pipeline]
# Name of the Pipeline that will be created.
# Note that an existing pipeline with this name will be dropped and recreated.
pipeline_name=testELKOrchestration

# IAM roles used by DataPipeline. 
# Note that existing IAM roles with this name will have their permission and trust policies updated.
pipeline_role=DataPipelineELKRole
pipeline_resource_role=DataPipelineELKResourceRole

# S3 path where you want to store logs from the pipeline; the S3 bucket is expected to be in the same region
# Include trailing slash
pipeline_log_location=roy-testbucket/

# Desied duration to wait for logs in S3 before pipeline is canceled
pipeline_timeout_minutes=60

######################################################################################################
# Pipeline objects definition
# Update the string values of the fields specified in their corresponding comment.
# Do not touch anything else.
######################################################################################################

# Settings
pipeline_settings={u'fields': [{u'stringValue': u'CASCADE', u'key': u'failureAndRerunMode'}, {u'stringValue': u'cron', u'key': u'scheduleType'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u's3://<pipeline_log_location>', u'key': u'pipelineLogUri'}, {u'stringValue': u'<pipeline_role>', u'key': u'role'}, {u'stringValue': u'<pipeline_resource_role>', u'key': u'resourceRole'}], u'id': u'Default', u'name': u'Default'}

# Schedule
#   startDateTime - change to desired time and future date
#   period - estimated run interval of the external job that places firewall logs in the S3 bucket
#          - must be a factor of 24 to maintain the pipeline starting everyday on the defined time on startDateTime
pipeline_schedule={u'fields': [{u'stringValue': u'2015-01-06T13:00:00', u'key': u'startDateTime'}, {u'stringValue': u'6 Hours', u'key': u'period'}, {u'stringValue': u'Schedule', u'key': u'type'}], u'id': u'DefaultSchedule', u'name': u'Run Every n Hours'}

# Resource
#   keyPair - EC2 key pair that exists within the region
#   subnetId - VPC subnet in which to place the control instance
#   imageId - AMI number of the Amazon Linux AMI compatible with t2.micro instances existing in the region
pipeline_resource={u'fields': [{u'stringValue': u'24 Hours', u'key': u'terminateAfter'}, {u'stringValue': u'<aws_region>', u'key': u'region'}, {u'stringValue': u'cascadeo20140812-stg', u'key': u'keyPair'}, {u'stringValue': u'subnet-eaa6109d', u'key': u'subnetId'}, {u'stringValue': u'<pipeline_resource_role>', u'key': u'resourceRole'}, {u'stringValue': u'Ec2Resource', u'key': u'type'}, {u'stringValue': u't2.micro', u'key': u'instanceType'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u'ami-b66ed3de', u'key': u'imageId'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'stringValue': u'<pipeline_role>', u'key': u'role'}], u'id': u'ResourceId_ht9V8', u'name': u'Control Instance'}

# Alarm For Failure
#   subject - intended subject of the notification on Failure
#   message - intended message content of the notification on Failure
pipeline_alarm_failure={u'fields': [{u'stringValue': u'ELK Failed', u'key': u'message'}, {u'stringValue': u'ELK Failed', u'key': u'subject'}, {u'stringValue': u'<topic_arn>', u'key': u'topicArn'}, {u'stringValue': u'<pipeline_role>', u'key': u'role'}, {u'stringValue': u'SnsAlarm', u'key': u'type'}], u'id': u'ActionId_BEaxi', u'name': u'Notify Failure'}

# Alarm For Success
#   subject - intended subject of the notification on Success
#   message - intended message content of the notification on Success
pipeline_alarm_success={u'fields': [{u'stringValue': u'ELK Workflow Completed Successfully', u'key': u'message'}, {u'stringValue': u'ELK Workflow Completed Successfully', u'key': u'subject'}, {u'stringValue': u'<topic_arn>', u'key': u'topicArn'}, {u'stringValue': u'<pipeline_role>', u'key': u'role'}, {u'stringValue': u'SnsAlarm', u'key': u'type'}], u'id': u'ActionId_kKmEb', u'name': u'Notify Success'}

# Alarm For Actual ELK Process Start
#   subject - intended subject of the notification on ELK Process Start
#   message - intended message content of the notification on Success
pipeline_alarm_start={u'fields': [{u'stringValue': u'ELK Workflow Starting', u'key': u'message'}, {u'stringValue': u'ELK Workflow Starting', u'key': u'subject'}, {u'stringValue': u'<topic_arn>', u'key': u'topicArn'}, {u'stringValue': u'<pipeline_role>', u'key': u'role'}, {u'stringValue': u'SnsAlarm', u'key': u'type'}], u'id': u'ActionId_zVzpg', u'name': u'Notify Start'}

# Pipeline termination action
# DO NOT TOUCH pipeline termination definition
pipeline_terminate={u'fields': [{u'stringValue': u'Terminate', u'key': u'type'}], u'id': u'ActionId_rRqPU', u'name': u'Cancel ELK Pipeline'}

# Preconditions
# DO NOT TOUCH Precondition objects definition

pipeline_precondition_s3_empty={u'fields': [{u'stringValue': u's3://<pipeline_log_location>#{name}/stdout.log', u'key': u'stdout'}, {u'stringValue': u's3://<script_path>check_s3_path_empty.py', u'key': u'scriptUri'}, {u'stringValue': u'30 Seconds', u'key': u'retryDelay'}, {u'stringValue': u's3://<pipeline_log_location>#{name}/stderr.log', u'key': u'stderr'}, {u'stringValue': u'ShellCommandPrecondition', u'key': u'type'}], u'id': u'PreconditionId_WIKik', u'name': u'Check S3 Empty'}

pipeline_precondition_s3_not_empty={u'fields': [{u'stringValue': u's3://<pipeline_log_location>#{name}/stdout.log', u'key': u'stdout'}, {u'stringValue': u'30 Seconds', u'key': u'retryDelay'}, {u'stringValue': u's3://<script_path>check_s3_path_not_empty.py', u'key': u'scriptUri'}, {u'stringValue': u's3://<pipeline_log_location>#{name}/stderr.log', u'key': u'stderr'}, {u'stringValue': u'ShellCommandPrecondition', u'key': u'type'}], u'id': u'PreconditionId_KUR9P', u'name': u'Check S3 Not Empty'}

pipeline_precondition_has_keys={u'fields': [{u'stringValue': u's3://<pipeline_log_location>#{name}/stdout.log', u'key': u'stdout'}, {u'stringValue': u's3://<script_path>check_logstash_buffer_not_empty.py', u'key': u'scriptUri'}, {u'stringValue': u'30 Seconds', u'key': u'retryDelay'}, {u'stringValue': u's3://<pipeline_log_location>#{name}/stderr.log', u'key': u'stderr'}, {u'stringValue': u'ShellCommandPrecondition', u'key': u'type'}], u'id': u'PreconditionId_1yIWo', u'name': u'Check Logstash Buffer Has keys'}

pipeline_precondition_logstash_buffer_empty={u'fields': [{u'stringValue': u's3://<pipeline_log_location>#{name}/stdout.log', u'key': u'stdout'}, {u'stringValue': u's3://<script_path>check_logstash_buffer_empty.py', u'key': u'scriptUri'}, {u'stringValue': u'30 Seconds', u'key': u'retryDelay'}, {u'stringValue': u's3://<pipeline_log_location>#{name}/stderr.log', u'key': u'stderr'}, {u'stringValue': u'ShellCommandPrecondition', u'key': u'type'}], u'id': u'PreconditionId_ZxKz2', u'name': u'Check Logstash Buffer Is Empty'}

# Activity Nodes
# DO NOT TOUCH Activity Nodes definition
pipeline_activity_wait_for_logs={u'fields': [{u'refValue': u'PreconditionId_KUR9P', u'key': u'precondition'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u"echo 'Pipeline Starts'", u'key': u'command'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'refValue': u'ActionId_zVzpg', u'key': u'onSuccess'}, {u'stringValue': u'<pipeline_timeout_minutes> Minutes', u'key': u'lateAfterTimeout'}, {u'refValue': u'ActionId_BEaxi', u'key': u'onFail'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}, {u'refValue': u'ActionId_rRqPU', u'key': u'onLateAction'}], u'id': u'ActivityId_KaYNf', u'name': u'Wait for Logs'}

pipeline_activity_scaleup_shipper_redis={u'fields': [{u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u's3://<script_path>scale_up_shipper_redis.py', u'key': u'scriptUri'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'refValue': u'ActionId_BEaxi', u'key': u'onFail'}, {u'refValue': u'ActivityId_KaYNf', u'key': u'dependsOn'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}], u'id': u'ActivityId_EcIg9', u'name': u'Scale up Shipper and Redis'}

pipeline_activity_scaleup_indexer={u'fields': [{u'refValue': u'PreconditionId_1yIWo', u'key': u'precondition'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u's3://<script_path>scale_up_indexer.py', u'key': u'scriptUri'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'refValue': u'ActionId_BEaxi', u'key': u'onFail'}, {u'refValue': u'ActivityId_KaYNf', u'key': u'dependsOn'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}], u'id': u'ActivityId_99eng', u'name': u'Scale up Indexer'}

pipeline_activity_scaledown_shipper={u'fields': [{u'refValue': u'PreconditionId_WIKik', u'key': u'precondition'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u's3://<script_path>scale_down_shipper.py', u'key': u'scriptUri'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'refValue': u'ActionId_BEaxi', u'key': u'onFail'}, {u'refValue': u'ActivityId_EcIg9', u'key': u'dependsOn'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}], u'id': u'ActivityId_BHxPl', u'name': u'Scale down Shipper '}

pipeline_activity_scaledown_redis_indexer={u'fields': [{u'refValue': u'PreconditionId_ZxKz2', u'key': u'precondition'}, {u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u's3://<script_path>scale_down_redis_indexer.py', u'key': u'scriptUri'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'refValue': u'ActionId_BEaxi', u'key': u'onFail'}, {u'refValue': u'ActivityId_99eng', u'key': u'dependsOn'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}], u'id': u'ActivityId_OdpYE', u'name': u'Scale down Redis and Indexer'}

pipeline_activity_notification={u'fields': [{u'refValue': u'DefaultSchedule', u'key': u'schedule'}, {u'stringValue': u"echo '' | crontab -;/usr/bin/aws cloudwatch put-metric-data --metric-name ELK --namespace Pipeline --value=0 --region us-east-1", u'key': u'command'}, {u'refValue': u'ResourceId_ht9V8', u'key': u'runsOn'}, {u'stringValue': u'1', u'key': u'maxActiveInstances'}, {u'stringValue': u'0', u'key': u'maximumRetries'}, {u'refValue': u'ActionId_kKmEb', u'key': u'onSuccess'}, {u'refValue': u'ActivityId_BHxPl', u'key': u'dependsOn'}, {u'refValue': u'ActivityId_OdpYE', u'key': u'dependsOn'}, {u'stringValue': u'ShellCommandActivity', u'key': u'type'}], u'id': u'ActivityId_YGYLL', u'name': u'Notification Activity'}
 
